{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d6f1a91",
   "metadata": {},
   "source": [
    "# Continue Training \n",
    "### Author: Yicheng Zhu yzhu19@smith.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac69616",
   "metadata": {},
   "source": [
    "This notebook is designed to restart the training from a specific round in case the program crashes at a late stage. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25080e6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from defines import *\n",
    "from model import *\n",
    "from data import *\n",
    "from filePrep import *\n",
    "from model_reader.modelreader import *\n",
    "from p2ctransformer.p2c import *\n",
    "import cv2\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import multiprocessing\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a2f8e8",
   "metadata": {},
   "source": [
    "import chosen migrator here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73184e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from migration_yz.migrator import *\n",
    "from migration_cl.migrator import *\n",
    "#from migration_cw.migrator import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0880857",
   "metadata": {},
   "source": [
    "edit K and batch size accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acd95a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 5\n",
    "batch_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe408c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(working_parent_folder,data_gen_args, queue):    \n",
    "    history = []\n",
    "    if_polar = False\n",
    "    if working_parent_folder == PARAM_PATH_TEMP_POLAR:\n",
    "        if_polar = True\n",
    "    \n",
    "    for i in range(K):\n",
    "        #working_test_folder_i = os.path.join(working_parent_folder, str(i), PARAM_SUB_FOLDER_CARTE)\n",
    "        temp_folder_path = os.path.join(working_parent_folder,'temp')\n",
    "        os.mkdir(temp_folder_path)\n",
    "        for j in range(K):\n",
    "            if i != j:\n",
    "                for subfolder_name in ['image','label']:\n",
    "                    if if_polar:\n",
    "                        subfolder_path = os.path.join(working_parent_folder,str(j),'polar',subfolder_name)\n",
    "                    else:\n",
    "                        subfolder_path = os.path.join(working_parent_folder,str(j),'carte',subfolder_name)\n",
    "                    temp_subfolder_path = os.path.join(temp_folder_path,subfolder_name)\n",
    "                    for root, dirs, files in os.walk(subfolder_path):\n",
    "                        for file in files:\n",
    "                            src_file = os.path.join(root, file)\n",
    "                            dest_file = os.path.join(temp_subfolder_path,os.path.relpath(src_file, subfolder_path))\n",
    "                            os.makedirs(os.path.dirname(dest_file), exist_ok=True)\n",
    "                            shutil.copy(src_file, dest_file)\n",
    "        test_gene = trainGenerator(batch_size, temp_folder_path, PARAM_IMG_FOLDER, PARAM_MSK_FOLDER, data_gen_args)\n",
    "        print('Now Training the Model for folder',i)\n",
    "        if if_polar:\n",
    "            print('Now in polar group')\n",
    "        else:\n",
    "            print('Now in Cartesian group')\n",
    "        model = unet(PARAM_BETA1[PARAM_BETA_TEST_NUM], PARAM_BETA2[PARAM_BETA_TEST_NUM]) \n",
    "        model_checkpoint_file = os.path.join(working_parent_folder,str(i),'checkpoint.hdf5')\n",
    "        model_checkpoint = ModelCheckpoint(model_checkpoint_file, monitor = 'loss', verbose=1, save_best_only=True)\n",
    "        keepGoing = True\n",
    "        force_restart_count = 0\n",
    "        force_restart_cumulative_count = 0\n",
    "        previou_min_loss = math.inf\n",
    "        while(keepGoing):\n",
    "            test_run = model.fit(test_gene, verbose = 1, steps_per_epoch = STEPS, epochs = EPOCHS, callbacks = [model_checkpoint])\n",
    "            force_restart_cumulative_count += EPOCHS\n",
    "            current_min = min(test_run.history['loss'])\n",
    "            if current_min <= previou_min_loss:\n",
    "                previou_min_loss = current_min\n",
    "                history.append(test_run)\n",
    "                force_restart_count = 0                \n",
    "            else:\n",
    "                if previou_min_loss < TRAIN_STOP_THRESHOLD: \n",
    "                    keepGoing = False\n",
    "                else:\n",
    "                    if force_restart_count >= FORCE_RESTART_TOLERANCE and force_restart_cumulative_count >= CUMULATIVE_STOP_TOLERANCE:\n",
    "                        force_restart_count = 0\n",
    "                        force_restart_cumulative_count = 0\n",
    "                        previou_min_loss = math.inf\n",
    "                        os.remove(model_checkpoint_file)\n",
    "                        model_checkpoint = ModelCheckpoint(model_checkpoint_file, monitor = 'loss', verbose=1, save_best_only=True)\n",
    "                        model = unet(PARAM_BETA1[PARAM_BETA_TEST_NUM], PARAM_BETA2[PARAM_BETA_TEST_NUM]) \n",
    "                    else:\n",
    "                        force_restart_count += 1\n",
    "                        model.load_weights(model_checkpoint_file)\n",
    "        shutil.rmtree(temp_folder_path)\n",
    "        loss_curve = []\n",
    "        for eachrun in history:\n",
    "            loss_curve.append(eachrun.history['loss'])\n",
    "    queue.put(loss_curve) \n",
    "\n",
    "def test(filematrix, queue):\n",
    "    n = filematrix.shape[0]\n",
    "    m = K * 2\n",
    "    scorematrix = np.zeros((n,m))\n",
    "    image_extension = 'tif'\n",
    "    augmented_filematrix = np.copy(filematrix)\n",
    "    for row in augmented_filematrix:\n",
    "        for for_counter in range(2):\n",
    "            zero_count = 0\n",
    "            for index in range(K):\n",
    "                real_index = index + for_counter * K\n",
    "                if row[real_index] == 0:\n",
    "                    zero_count += 1\n",
    "            if zero_count == 5:\n",
    "                row[for_counter*K:for_counter*K + 5] = 1\n",
    "    row_indices, col_indices = np.where(augmented_filematrix == 1)\n",
    "    indices = list(zip(row_indices, col_indices))\n",
    "    scorematrix = np.zeros((n,m))\n",
    "    for img_type in ['polar', 'carte']:\n",
    "        for_counter = 0\n",
    "        if img_type == 'polar':\n",
    "            working_parent_folder = PARAM_PATH_TEMP_POLAR\n",
    "            src_folder = PARAM_PATH_POLAR\n",
    "        else:\n",
    "            working_parent_folder = PARAM_PATH_TEMP_CARTE\n",
    "            src_folder = PARAM_PATH_CARTE\n",
    "            for_counter = 1\n",
    "            \n",
    "        for i in range(K):\n",
    "            current_folder_index = i + for_counter * K\n",
    "            temp_test_folder_name = 'temptest'\n",
    "            #print(working_parent_folder)\n",
    "                \n",
    "            if os.path.exists(temp_test_folder_name):\n",
    "                shutil.rmtree(temp_test_folder_name)\n",
    "            temp_test_img_folder = os.path.join(temp_test_folder_name,PARAM_IMG_FOLDER)\n",
    "            temp_test_msk_folder = os.path.join(temp_test_folder_name,PARAM_MSK_FOLDER)\n",
    "            os.makedirs(temp_test_img_folder)\n",
    "            os.makedirs(temp_test_msk_folder)\n",
    "        \n",
    "            for indice in indices:\n",
    "                if indice[1] == current_folder_index:\n",
    "                    img_name = str(indice[0]) + '.' + image_extension\n",
    "                    src = os.path.join(src_folder,PARAM_IMG_FOLDER,img_name)\n",
    "                    shutil.copy2(src, temp_test_img_folder)\n",
    "                    src = os.path.join(src_folder,PARAM_MSK_FOLDER,img_name)\n",
    "                    shutil.copy2(src, temp_test_msk_folder)\n",
    "            model_path = os.path.join(working_parent_folder, str(i), 'checkpoint.hdf5')\n",
    "            print('Now working with path', model_path)\n",
    "            current_model = unet(PARAM_BETA1[PARAM_BETA_TEST_NUM], PARAM_BETA2[PARAM_BETA_TEST_NUM])\n",
    "            current_model.load_weights(model_path) \n",
    "            for test_image_name in os.listdir(temp_test_img_folder):\n",
    "                test_image_name_raw, ext = os.path.splitext(test_image_name)\n",
    "                image_path = os.path.join(temp_test_img_folder, test_image_name)\n",
    "                ground_truth_mask_path = os.path.join(temp_test_msk_folder, test_image_name)\n",
    "                \n",
    "                test_image = cv2.imread(image_path)\n",
    "                test_image = cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB)\n",
    "                test_image = test_image / 255.0\n",
    "                test_image = np.expand_dims(test_image,axis = 0)\n",
    "\n",
    "                ground_truth_mask = cv2.imread(ground_truth_mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "                ground_truth_mask = ground_truth_mask / 255.0\n",
    "                ground_truth_mask = ground_truth_mask.astype(np.uint8)\n",
    "                ###HERE IS WHERE PREDICT AND GENERATE SCORE\n",
    "                prediction = current_model.predict(test_image, verbose = 0)\n",
    "                \n",
    "                threshold = 0.5\n",
    "                binary_mask = (prediction > threshold).astype(np.uint8)\n",
    "                binary_mask = binary_mask[0,:,:,0]\n",
    "                if img_type == 'polar':\n",
    "                    dice = dice_coefficient(ground_truth_mask, binary_mask)\n",
    "                else:\n",
    "                    dice = dice_coefficient_carte(ground_truth_mask, binary_mask)\n",
    "                ###REPLACE WITH QUICK SCORE GENERATOR TO DEBUG THE ITERATION GROUP\n",
    "                ###HERE IS THE QUICK SCORE GENERATOR \n",
    "                #dice = random.random()\n",
    "                ###REPLACE WITH REAL PREDICT BLOCK FOR NORMAL ACTION\n",
    "                scorematrix[int(test_image_name_raw), current_folder_index] = dice   \n",
    "    queue.put(scorematrix)\n",
    "         \n",
    "def test_allinc(filematrix, queue):\n",
    "    n = filematrix.shape[0]\n",
    "    m = K * 2\n",
    "    scorematrix = np.zeros((n,m))\n",
    "    trans_dic = p2c_dic_gen(127, 127, 256, 256)\n",
    "    image_extension = 'tif'\n",
    "    augmented_filematrix = np.copy(filematrix)\n",
    "    for row in augmented_filematrix:\n",
    "        for for_counter in range(2):\n",
    "            zero_count = 0\n",
    "            for index in range(K):\n",
    "                real_index = index + for_counter * K\n",
    "                if row[real_index] == 0:\n",
    "                    zero_count += 1\n",
    "            if zero_count == 5:\n",
    "                row[for_counter*K:for_counter*K + 5] = 1\n",
    "    row_indices, col_indices = np.where(augmented_filematrix == 1)\n",
    "    indices = list(zip(row_indices, col_indices))\n",
    "    scorematrix = np.zeros((n,m))\n",
    "    for img_type in ['polar', 'carte']:\n",
    "        for_counter = 0\n",
    "        ground_truth_src_folder = PARAM_PATH_CARTE\n",
    "        if img_type == 'polar':\n",
    "            working_parent_folder = PARAM_PATH_TEMP_POLAR\n",
    "            src_folder = PARAM_PATH_POLAR\n",
    "        else:\n",
    "            working_parent_folder = PARAM_PATH_TEMP_CARTE\n",
    "            src_folder = PARAM_PATH_CARTE\n",
    "            for_counter = 1\n",
    "            \n",
    "        for i in range(K):\n",
    "            current_folder_index = i + for_counter * K\n",
    "            temp_test_folder_name = 'temptest'\n",
    "            #print(working_parent_folder)\n",
    "                \n",
    "            if os.path.exists(temp_test_folder_name):\n",
    "                shutil.rmtree(temp_test_folder_name)\n",
    "            temp_test_img_folder = os.path.join(temp_test_folder_name,PARAM_IMG_FOLDER)\n",
    "            temp_test_msk_folder = os.path.join(temp_test_folder_name,PARAM_MSK_FOLDER)\n",
    "            os.makedirs(temp_test_img_folder)\n",
    "            os.makedirs(temp_test_msk_folder)\n",
    "        \n",
    "            for indice in indices:\n",
    "                if indice[1] == current_folder_index:\n",
    "                    img_name = str(indice[0]) + '.' + image_extension\n",
    "                    src = os.path.join(src_folder,PARAM_IMG_FOLDER,img_name)\n",
    "                    shutil.copy2(src, temp_test_img_folder)\n",
    "                    src = os.path.join(ground_truth_src_folder,PARAM_MSK_FOLDER,img_name)\n",
    "                    shutil.copy2(src, temp_test_msk_folder)\n",
    "            model_path = os.path.join(working_parent_folder, str(i), 'checkpoint.hdf5')\n",
    "            print('Now working with path', model_path)\n",
    "            current_model = unet(PARAM_BETA1[PARAM_BETA_TEST_NUM], PARAM_BETA2[PARAM_BETA_TEST_NUM])\n",
    "            current_model.load_weights(model_path) \n",
    "            for test_image_name in os.listdir(temp_test_img_folder):\n",
    "                test_image_name_raw, ext = os.path.splitext(test_image_name)\n",
    "                image_path = os.path.join(temp_test_img_folder, test_image_name)\n",
    "                ground_truth_mask_path = os.path.join(temp_test_msk_folder, test_image_name)\n",
    "                \n",
    "                test_image = cv2.imread(image_path)\n",
    "                test_image = cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB)\n",
    "                test_image = test_image / 255.0\n",
    "                test_image = np.expand_dims(test_image,axis = 0)\n",
    "\n",
    "                ground_truth_mask = cv2.imread(ground_truth_mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "                ground_truth_mask = ground_truth_mask / 255.0\n",
    "                ground_truth_mask = ground_truth_mask.astype(np.uint8)\n",
    "                ###HERE IS WHERE PREDICT AND GENERATE SCORE\n",
    "                prediction = current_model.predict(test_image, verbose = 0)\n",
    "                threshold = 0.5\n",
    "                binary_mask = (prediction > threshold).astype(np.uint8)\n",
    "                binary_mask = binary_mask[0,:,:,0]\n",
    "                if img_type == 'polar':\n",
    "                    binary_mask = p2c(binary_mask, trans_dic)\n",
    "                dice = dice_coefficient_carte(ground_truth_mask, binary_mask)\n",
    "                ###REPLACE WITH QUICK SCORE GENERATOR TO DEBUG THE ITERATION GROUP\n",
    "                ###HERE IS THE QUICK SCORE GENERATOR \n",
    "                #dice = random.random()\n",
    "                ###REPLACE WITH REAL PREDICT BLOCK FOR NORMAL ACTION\n",
    "                scorematrix[int(test_image_name_raw), current_folder_index] = dice   \n",
    "    queue.put(scorematrix)\n",
    "\n",
    "def train_and_test_last_round(migrating_wizard):\n",
    "    split = migrating_wizard.get_loc_current()\n",
    "    \n",
    "    true_indices = np.where(split)[0]\n",
    "    false_indices = np.where(~split)[0]\n",
    "    if os.path.exists('./temp_lastround'):\n",
    "        shutil.rmtree('./temp_lastround')\n",
    "    os.makedirs('./temp_lastround/cartesian_Dom/image')\n",
    "    os.makedirs('./temp_lastround/cartesian_Dom/label')\n",
    "    os.makedirs('./temp_lastround/polar_Dom/image')\n",
    "    os.makedirs('./temp_lastround/polar_Dom/label')\n",
    "    \n",
    "    i = 0\n",
    "    for item in true_indices:\n",
    "        img_name = str(item) + '.tif'\n",
    "        src = os.path.join(PARAM_PATH_POLAR, PARAM_IMG_FOLDER, img_name)\n",
    "        shutil.copy2(src, os.path.join('./temp_lastround/polar_Dom/image'))\n",
    "        src = os.path.join(PARAM_PATH_POLAR, PARAM_MSK_FOLDER, img_name)\n",
    "        shutil.copy2(src, os.path.join('./temp_lastround/polar_Dom/label'))\n",
    "    for item in false_indices:\n",
    "        img_name = str(item) + '.tif'\n",
    "        src = os.path.join(PARAM_PATH_CARTE, PARAM_IMG_FOLDER, img_name)\n",
    "        shutil.copy2(src, os.path.join('./temp_lastround/cartesian_Dom/image'))\n",
    "        src = os.path.join(PARAM_PATH_CARTE, PARAM_MSK_FOLDER, img_name)\n",
    "        shutil.copy2(src, os.path.join('./temp_lastround/cartesian_Dom/label'))\n",
    "    polar_data_gen_args = POLAR_GEN_ARGS\n",
    "    polar_train_gene = trainGenerator(batch_size, './temp_lastround/polar_Dom', PARAM_IMG_FOLDER, PARAM_MSK_FOLDER, polar_data_gen_args)\n",
    "    polar_model = unet(PARAM_BETA1[PARAM_BETA_TEST_NUM], PARAM_BETA2[PARAM_BETA_TEST_NUM])\n",
    "    polar_model_checkpoint_file = './temp_lastround/polar_Dom/checkpoint.hdf5'\n",
    "    polar_model_checkpoint = ModelCheckpoint(polar_model_checkpoint_file, monitor = 'loss', verbose=1, save_best_only=True)\n",
    "\n",
    "    force_restart_cumulative_count = 0\n",
    "    force_restart_count = 0\n",
    "    previou_min_loss = math.inf\n",
    "    keepGoing = True\n",
    "    while(keepGoing):\n",
    "        test_run = polar_model.fit(polar_train_gene, verbose = 1, steps_per_epoch = STEPS, epochs = EPOCHS, callbacks = [polar_model_checkpoint])\n",
    "        force_restart_cumulative_count += EPOCHS\n",
    "        current_min = min(test_run.history['loss'])\n",
    "        if current_min <= previou_min_loss:\n",
    "            previou_min_loss = current_min\n",
    "            force_restart_count = 0                \n",
    "        else:\n",
    "            if previou_min_loss < TRAIN_STOP_THRESHOLD: \n",
    "                keepGoing = False\n",
    "            else:\n",
    "                if force_restart_count >= FORCE_RESTART_TOLERANCE and force_restart_cumulative_count >= CUMULATIVE_STOP_TOLERANCE:\n",
    "                    force_restart_count = 0\n",
    "                    force_restart_cumulative_count = 0\n",
    "                    previou_min_loss = math.inf\n",
    "                    os.remove(polar_model_checkpoint_file)\n",
    "                    polar_model_checkpoint = ModelCheckpoint(polar_model_checkpoint_file, monitor = 'loss', verbose=1, save_best_only=True)\n",
    "                    polar_model = unet(PARAM_BETA1[PARAM_BETA_TEST_NUM], PARAM_BETA2[PARAM_BETA_TEST_NUM]) \n",
    "                else:\n",
    "                    force_restart_count += 1\n",
    "                    polar_model.load_weights(polar_model_checkpoint_file)\n",
    "\n",
    "    polar_test_gene = testGenerator('./data/endoscopic_test956/polar', PARAM_IMG_FOLDER, PARAM_MSK_FOLDER)\n",
    "    polar_results = polar_model.predict_generator(polar_test_gene, 956, verbose=1)\n",
    "    np.save('./results/polar_prediction.npy',polar_results)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    carte_data_gen_args = CARTE_GEN_ARGS\n",
    "    carte_train_gene = trainGenerator(batch_size, './temp_lastround/cartesian_Dom', PARAM_IMG_FOLDER, PARAM_MSK_FOLDER, carte_data_gen_args)\n",
    "    carte_model = unet(PARAM_BETA1[PARAM_BETA_TEST_NUM], PARAM_BETA2[PARAM_BETA_TEST_NUM])\n",
    "    carte_model_checkpoint_file = './temp_lastround/cartesian_Dom/checkpoint.hdf5'\n",
    "    carte_model_checkpoint = ModelCheckpoint(carte_model_checkpoint_file, monitor = 'loss', verbose=1, save_best_only=True)\n",
    "\n",
    "    force_restart_cumulative_count = 0\n",
    "    force_restart_count = 0\n",
    "    previou_min_loss = math.inf\n",
    "    keepGoing = True\n",
    "    while(keepGoing):\n",
    "        test_run = carte_model.fit(carte_train_gene, verbose = 1, steps_per_epoch = STEPS, epochs = EPOCHS, callbacks = [carte_model_checkpoint])\n",
    "        force_restart_cumulative_count += EPOCHS\n",
    "        current_min = min(test_run.history['loss'])\n",
    "        if current_min <= previou_min_loss:\n",
    "            previou_min_loss = current_min\n",
    "            force_restart_count = 0                \n",
    "        else:\n",
    "            if previou_min_loss < TRAIN_STOP_THRESHOLD: \n",
    "                keepGoing = False\n",
    "            else:\n",
    "                if force_restart_count >= FORCE_RESTART_TOLERANCE and force_restart_cumulative_count >= CUMULATIVE_STOP_TOLERANCE:\n",
    "                    force_restart_count = 0\n",
    "                    force_restart_cumulative_count = 0\n",
    "                    previou_min_loss = math.inf\n",
    "                    os.remove(carte_model_checkpoint_file)\n",
    "                    carte_model_checkpoint = ModelCheckpoint(carte_model_checkpoint_file, monitor = 'loss', verbose=1, save_best_only=True)\n",
    "                    carte_model = unet(PARAM_BETA1[PARAM_BETA_TEST_NUM], PARAM_BETA2[PARAM_BETA_TEST_NUM]) \n",
    "                else:\n",
    "                    force_restart_count += 1\n",
    "                    carte_model.load_weights(carte_model_checkpoint_file)\n",
    "    \n",
    "    carte_test_gene = testGenerator('./data/endoscopic_test956/cartesian', PARAM_IMG_FOLDER, PARAM_MSK_FOLDER)\n",
    "    carte_results = carte_model.predict_generator(carte_test_gene, 956, verbose=1)\n",
    "    np.save('./results/carte_prediction.npy',carte_results)\n",
    "\n",
    "def train_2K_models(round):        \n",
    "    queue = multiprocessing.Queue()\n",
    "    data_gen_args = POLAR_GEN_ARGS\n",
    "    PP = multiprocessing.Process(target=train, args= ([PARAM_PATH_TEMP_POLAR, data_gen_args, queue]))\n",
    "    PP.start()\n",
    "    polar_history = queue.get()\n",
    "    PP.join()\n",
    "    \n",
    "    data_gen_args = CARTE_GEN_ARGS\n",
    "    PC = multiprocessing.Process(target=train, args= ([PARAM_PATH_TEMP_CARTE, data_gen_args, queue]))\n",
    "    PC.start()\n",
    "    carte_history = queue.get()\n",
    "    PC.join()\n",
    "    #model_PNGgen(polar_history, carte_history, round)\n",
    "    #print(polar_history)\n",
    "    model_npyStore(polar_history,carte_history,round)\n",
    "    \n",
    "def model_npyStore(polar_history, carte_history, round):\n",
    "    models_history_path = os.path.join(PARAM_RESULTS,'models_history/round_'+str(round))\n",
    "    os.makedirs(models_history_path, exist_ok = True)\n",
    "    np_p_history = np.asarray(polar_history)\n",
    "    np_c_history = np.asarray(carte_history)\n",
    "    np_p_history_path = os.path.join(models_history_path, 'polar_history.npy')\n",
    "    np_c_history_path = os.path.join(models_history_path, 'carte_history.npy')\n",
    "    np.save(np_p_history_path,np_p_history)\n",
    "    np.save(np_c_history_path,np_c_history)\n",
    "    \n",
    "\n",
    "\n",
    "def model_PNGgen(polar_history,carte_history,round):\n",
    "    models_path = os.path.join(PARAM_RESULTS,'models/round_'+str(round))\n",
    "    os.makedirs(models_path, exist_ok = True)\n",
    "    i=0\n",
    "    for single_run in polar_history:\n",
    "        plt.plot(single_run.history['loss'])\n",
    "        plt.plot(single_run.history['accuracy'])\n",
    "        plt.title('Polar Run')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['loss', 'accuracy'], loc='upper left')\n",
    "        plt.savefig(os.path.join(models_path,'polar_'+str(i)+'.jpg'))\n",
    "        i+=1\n",
    "\n",
    "    i =0\n",
    "    for single_run in carte_history:\n",
    "        plt.plot(single_run.history['loss'])\n",
    "        plt.plot(single_run.history['accuracy'])\n",
    "        plt.title('Cartesian Run')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['loss', 'accuracy'], loc='upper left')\n",
    "        plt.savefig(os.path.join(models_path,'carte_'+str(i)+'.jpg'))    \n",
    "        i+=1\n",
    "    print(\"models saved\")\n",
    "\n",
    "def dice_coefficient(image1, image2):#Generate the Dice coefficient of two binary images, should do thresholding before inputting\n",
    "    # Ensure the input images have the same shape\n",
    "    smooth = 1\n",
    "    if image1.shape != image2.shape:\n",
    "        raise ValueError(\"Input images must have the same shape.\")\n",
    "    image1 = np.matrix(image1)\n",
    "    image2 = np.matrix(image2)\n",
    "    img1_f = (~image1.astype(bool)).astype(int)\n",
    "    img2_f = (~image2.astype(bool)).astype(int)\n",
    "    # Calculate the intersection (logical AND) between the two binary images\n",
    "    intersection_o = np.logical_and(image1, image2).sum()\n",
    "    intersection_f = np.logical_and(img1_f, img2_f).sum()\n",
    "    #print(intersection_o,intersection_f)\n",
    "    # Calculate the sum of pixels in each image\n",
    "    sum_image1_o = image1.sum()\n",
    "    sum_image2_o = image2.sum()\n",
    "    #print(sum_image1_o,sum_image2_o)\n",
    "    sum_image1_f = img1_f.sum()\n",
    "    sum_image2_f = img2_f.sum()\n",
    "    #print(sum_image1_f,sum_image2_f)\n",
    "   \n",
    "    # Calculate the Dice coefficient\n",
    "    dice = (2.0 * intersection_o + smooth) / (sum_image1_o + sum_image2_o + smooth)\n",
    "    #print('dice',dice)\n",
    "    dice_f = (2.0 * intersection_f + smooth) / (sum_image1_f + sum_image2_f + smooth)\n",
    "    #print('dice_f',dice_f)\n",
    "    dice_avg = (dice + dice_f) / 2.0\n",
    "    #print('dice_avg', dice_avg)\n",
    "    return dice_avg\n",
    "\n",
    "def dice_coefficient_carte(image1, image2):#Generate the Dice coefficient of two binary images, should do thresholding before inputting\n",
    "    # Ensure the input images have the same shape\n",
    "    smooth = 1\n",
    "    if image1.shape != image2.shape:\n",
    "        raise ValueError(\"Input images must have the same shape.\")\n",
    "    image1 = np.matrix(image1)\n",
    "    image2 = np.matrix(image2)\n",
    "    img1_f = (~image1.astype(bool)).astype(int)\n",
    "    img2_f = (~image2.astype(bool)).astype(int)\n",
    "    # Calculate the intersection (logical AND) between the two binary images\n",
    "    intersection_o = np.logical_and(image1, image2).sum()\n",
    "    intersection_f = np.logical_and(img1_f, img2_f).sum()\n",
    "    #print(intersection_o,intersection_f)\n",
    "    # Calculate the sum of pixels in each image\n",
    "    sum_image1_o = image1.sum()\n",
    "    sum_image2_o = image2.sum()\n",
    "    #print(sum_image1_o,sum_image2_o)\n",
    "    sum_image1_f = img1_f.sum()\n",
    "    sum_image2_f = img2_f.sum()\n",
    "    #print(sum_image1_f,sum_image2_f)\n",
    "   \n",
    "    # Calculate the Dice coefficient\n",
    "    dice = (2.0 * intersection_o + smooth) / (sum_image1_o + sum_image2_o + smooth)\n",
    "    #print('dice',dice)\n",
    "    dice_f = (2.0 * (intersection_f - 14616) + smooth) / (sum_image1_f + sum_image2_f + smooth - 29232) #Hard-coded numbers here, need to prove \n",
    "    #print('dice_f',dice_f)\n",
    "    dice_avg = (dice + dice_f) / 2.0\n",
    "    #print('dice_avg', dice_avg)\n",
    "    return dice_avg\n",
    "\n",
    "def make_K_folds(polar_indices,carte_indices,K):\n",
    "    checkNcreateTempFolder(PARAM_PATH_TEMP_POLAR, K)\n",
    "    checkNcreateTempFolder(PARAM_PATH_TEMP_CARTE, K)\n",
    "\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
    "\n",
    "    i = 0\n",
    "    for train_indices, test_indices_P in kfold.split(polar_indices):\n",
    "        fillFolder(test_indices_P, polar_indices, PARAM_PATH_POLAR, PARAM_PATH_CARTE, PARAM_PATH_TEMP_POLAR, i)\n",
    "        print('Polar temp folder', i, 'created')\n",
    "        i += 1\n",
    "    i = 0\n",
    "    for train_indices, test_indices_C in kfold.split(carte_indices):\n",
    "        fillFolder(test_indices_C, carte_indices, PARAM_PATH_POLAR, PARAM_PATH_CARTE, PARAM_PATH_TEMP_CARTE, i)\n",
    "        print('Cartesian temp folder', i, 'created')\n",
    "        i += 1\n",
    "    return filematrixPNG_gen(K)\n",
    "\n",
    "\n",
    "def filematrixPNG_gen(K):\n",
    "    image_extension = 'tif'\n",
    "    img_pattern = os.path.join(PARAM_PATH_POLAR, PARAM_IMG_FOLDER, f'*.{image_extension}')\n",
    "    image_files = glob.glob(img_pattern)\n",
    "    n = len(image_files)\n",
    "    m = K * 2\n",
    "    filematrix = np.zeros((n,m))\n",
    "    for img_type in ['polar', 'carte']:\n",
    "        for_counter = 0\n",
    "        if img_type == 'polar':\n",
    "            working_parent_folder = PARAM_PATH_TEMP_POLAR\n",
    "        else:\n",
    "            working_parent_folder = PARAM_PATH_TEMP_CARTE\n",
    "            for_counter = 1\n",
    "        for i in range(K):\n",
    "            image_path = os.path.join(working_parent_folder, str(i), img_type, PARAM_IMG_FOLDER)\n",
    "            img_pattern = os.path.join(image_path, f'*.{image_extension}')\n",
    "            image_files = glob.glob(img_pattern)\n",
    "            for file_name in image_files:\n",
    "                file_name_shorten = os.path.basename(file_name)\n",
    "                file_name_raw, ext = os.path.splitext(file_name_shorten)\n",
    "                filematrix[int(file_name_raw),i + for_counter * K] = 1\n",
    "            #number_of_ones = np.count_nonzero(filematrix == 1)\n",
    "            #print(number_of_ones)  #uncomment this line when png file is not satisfactory, we can track the number of ones during each step  \n",
    "    \n",
    "    # filematrix_name = 'filematrix/filematrix_round_'+str(round)+'.png'\n",
    "    # filematrix_path = os.path.join(PARAM_RESULTS,filematrix_name)\n",
    "    # plt.imsave(filematrix_path, file_matrix, cmap = 'binary')\n",
    "    print('File Location saved as filematrix.png')\n",
    "    return filematrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aacd62f",
   "metadata": {},
   "source": [
    "# Main method below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d072a989",
   "metadata": {},
   "source": [
    "Change *current round* and *total round* value accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "126ad226",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_round = 13\n",
    "total_round = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78102a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.system(\"tree -d\")\n",
    "is_first_round = True\n",
    "while current_round <= total_round:\n",
    "# step1: file relocation \n",
    "    print('Now is round', current_round)\n",
    "    if is_first_round:\n",
    "        is_first_round = False\n",
    "        one_folder = os.path.join(PARAM_PATH_CARTE,PARAM_IMG_FOLDER)\n",
    "        file_list = os.listdir(one_folder)\n",
    "        n = len(file_list)\n",
    "        migrating_wizard = migrator(n, K)\n",
    "        first_split = migrating_wizard.get_loc_current()\n",
    "        true_indices = np.where(first_split)[0]\n",
    "        false_indices = np.where(~first_split)[0]\n",
    "        file_matrix = make_K_folds(true_indices,false_indices,K)\n",
    "\n",
    "\n",
    "    else:\n",
    "        split = migrating_wizard.get_loc_current()\n",
    "        true_indices = np.where(split)[0]\n",
    "        false_indices = np.where(~split)[0]\n",
    "        file_matrix = make_K_folds(true_indices,false_indices,K)\n",
    "\n",
    "    filematrix_name = 'filematrix/filematrix_round_'+str(current_round)+'.png'\n",
    "    filematrix_path = os.path.join(PARAM_RESULTS,filematrix_name)\n",
    "    plt.imsave(filematrix_path, file_matrix, cmap = 'binary')\n",
    "\n",
    "    #now that we have all the temporary folders ready, we train the ten models\n",
    "    train_2K_models(current_round)\n",
    "\n",
    "    #model_PNGgen(polar_history,carte_history,current_round)\n",
    "    queue = multiprocessing.Queue()\n",
    "    PT = multiprocessing.Process(target=test_allinc,args=([file_matrix,queue]))\n",
    "    PT.start()\n",
    "    scorematrix = queue.get()\n",
    "    PT.join()\n",
    "    scorematrix_name = 'scorematrix/scorematrix_round_' + str(current_round) + '.npy'\n",
    "    scorematrix_path = os.path.join(PARAM_RESULTS,scorematrix_name)\n",
    "    np.save(scorematrix_path, scorematrix)\n",
    "\n",
    "    #this is yz method\n",
    "    migrating_wizard.decide_and_mod_prob(scorematrix)\n",
    "    migrating_wizard.migrate()\n",
    "    #End of yz method\n",
    "\n",
    "    #starting here is cl method\n",
    "    #dif, decision = migrating_wizard.get_decision(K, scorematrix)\n",
    "    #count_p2c_c2p = migrating_wizard.decide_move(2000, dif, decision)\n",
    "    #count_p2c_c2p = migrating_wizard.decide_move_all(dif, decision) #This is using the moving all strategy\n",
    "    #End of cl method\n",
    "\n",
    "    #Start of cw method\n",
    "    #migrating_wizard.migrate(scorematrix)\n",
    "    #End of cw method\n",
    "\n",
    "    history = migrating_wizard.get_loc_history()\n",
    "    history_name = 'history/history_round_' + str(current_round) + '.npy'\n",
    "    history_path = os.path.join(PARAM_RESULTS,history_name)\n",
    "    np.save(history_path, history)\n",
    "    #uncomment if yz method\n",
    "    prob_history = migrating_wizard.get_prob_history() \n",
    "    prob_history_name = 'prob_history/prob_history_round_' + str(current_round) + '.npy'\n",
    "    prob_history_path = os.path.join(PARAM_RESULTS,prob_history_name)\n",
    "    np.save(prob_history_path, prob_history)\n",
    "train_and_test_last_round(migrating_wizard)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
